https://onnxruntime.ai/docs/api/python/api_summary.html

Execution Providers; 
https://onnxruntime.ai/docs/execution-providers/


Loading the model: InferenceSession Constructor:
https://onnxruntime.ai/docs/api/python/api_summary.html#inferencesession

Running the Model (InferenceSession method): 
https://onnxruntime.ai/docs/api/python/api_summary.html#onnxruntime.InferenceSession.run
